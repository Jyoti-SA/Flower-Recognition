<!doctype html>
<html  lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Reconocimiento de Flores</title>

		<meta name="description" content="Reconocimiento de distintas clases de objetos usando OpenCV y scikit-learn">
		<meta name="author" content="Braulio Vargas López">
		<meta name="author" content="Marta Gómez Macías">
		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/solarized.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Fuentes molonas con iconos para la presentación -->
		<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
 
		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-transition="zoom">
					<h2>Reconocimiento de especies de flores</h2>
					<p>
						<small>Creado por <a href="https://github.com/mgmacias95">Marta Gómez</a> y <a href="https://github.com/BraulioV">Braulio Vargas</a></small>
					</p>
					<p style="margin-top: 5%">
						<a href="https://github.com/mgmacias95" style="float:left"><i class="fa fa-github fa-2x" aria-hidden="true"></i> @mgmacias95</a>
						<a href="https://github.com/BraulioV" style="float:right"><i class="fa fa-github fa-2x" aria-hidden="true"></i> @BraulioV</a>
					</p>
				</section>
				<section data-transition="zoom">
					<h2 style="float: left; text-align;">Índice</h2>
					<ul style="float: right; text-align: right;">
						<li class="fragment" data-fragment-index="0">Descripción e interés del problema.</li>
						<li class="fragment" data-fragment-index="1">Descripción de la implementación.</li>
						<li class="fragment" data-fragment-index="2">Descripción de las imágenes usadas.</li>
						<li class="fragment" data-fragment-index="3">Descripción de los resultados.</li>
						<li class="fragment" data-fragment-index="4">Conclusiones.</li>
					</ul>
				</section>
				<section data-transition="zoom">
					<h2>Descripción e interés del problema</h2>

					<div class="fragment" data-fragment-index="0">Nuestro problema consiste en poder identificar y clasificar 17 clases distintas de flores británicas.</div>
					<div class="fragment" data-fragment-index="1" style="float:left">
						<ul>
							<li>Daffodil</li>
							<li>Snowdrop</li>
							<li>LillyValley</li>
							<li>BlueBell</li>
							<li>Crocus</li>
							<li>Iris</li>
							<li>Tigerlily</li>
							<li>Tulip</li>
						</ul>
					</div>
					<div class="fragment" data-fragment-index="1" style="float:right">
						<ul>
							<li>Fritillary</li>
							<li>Sunflower</li>
							<li>Daisy</li>
							<li>Colt'sFoot</li>
							<li>Dandelion</li>
							<li>Cowslip</li>
							<li>Buttercup</li>
							<li>Windflower</li>
							<li>Pansy</li>
						</ul>
					</div>
				</section>
				<section>
					<section data-transition="zoom">
						<h2>Descripción de la implementación</h2>
						<ul>
							<li class="fragment" data-fragment="0">Implementado en <i>Python</i>.</li>
							<li class="fragment" data-fragment="1">Usando <i>OpenCV</i> para la extracción de características.</li>
							<li class="fragment" data-fragment="2"><i>Scikit-learn</i> para la parte de aprendizaje automático.</li>
							<li class="fragment" data-fragment="3">Hemos hecho tres aproximaciones diferentes para obtener las características: basándonos en la forma de la flor, basándonos en el color de la flor y usando la información obtenida en ambas aproximaciones</li>
						</ul>
					</section>
					<section>
						<h2>Extracción de características</h2>
						<ul>
							<li class="fragment" data-fragment="0">Para detección de puntos clave hemos usado los descriptores SIFT, SURF y KAZE.</li>
							<li class="fragment" data-fragment="1"> Para obtener el BOW, ejecutamos un algoritmo K-Means sobre los descriptores de los puntos claves detectados. Para ello usamos <code>BOWKMeansTrainer</code> y <code>cluster</code> de OpenCV.</li>
							<li class="fragment" data-fragment="2">Computamos los histogramas de respuestas a las palabras para cada imagen, obteniendo el descriptor de estas. Para ello usamos <code>BOWImgDescriptorExtractor</code>.</li>
							<li class="fragment" data-fragment="3">Para trabajar con el color, hemos convertido las imágenes al espacio de color HSV y hemos simplificado los colores usando <i>Color Quantization</i></li>
						</ul>
					</section>
					<section>
						<div>
							<img src="img/SIFT.jpg" style="float: left; width: 45%; height: 45%">
							<img src="img/SURF.jpg" style="float: right; width: 45%; height: 45%">
						</div>
						<div>
							<img src="img/KAZE.jpg" style="float: center; width: 45%; height: 45%">
						</div>
					</section>
					<section>
						<h2>Aprendizaje Automático</h2>
						<ul>
							<li class="fragment" data-fragment="0">Hemos usado dos algoritmos de aprendizaje automático con dos variantes distintas cada uno:</li>
							<li class="fragment" data-fragment="1">Support Vector Machine</li>
							<ul>
								<li class="fragment" data-fragment="1">One VS One</li>
								<li class="fragment" data-fragment="1">One VS All</li>
							</ul>
							<li class="fragment" data-fragment="2">Random Forest</li>
							<li class="fragment" data-fragment="2">Boosting</li>
							<li>Los modelos se entrenarán haciendo validación cruzada debido a que solo disponemos de 1360 imágenes.</li>
						</ul>
					</section>
				</section>
				<section data-transition="zoom">
					<section>
						<h2>Descripción de las imágenes usadas</h2>
						<img src="Dataset/image_0004.jpg" style="width:45%">
						<img src="ColorQuantization/image_0004.jpg" style="width:45%">
					</section>
					<section>
						<h2>Descripción de las imágenes usadas</h2>
						<img src="Dataset/image_0481.jpg" style="width:45%">
						<img src="ColorQuantization/image_0481.jpg" style="width:45%">
					</section>
					<section>
						<h2>Descripción de las imágenes usadas</h2>
						<img src="Dataset/image_0853.jpg" style="width:45%">
						<img src="ColorQuantization/image_0853.jpg" style="width:45%">
					</section>
				</section>
				<section data-transition="zoom">
					<section>
						<h2>Resultados</h2>
						<figure>
							<img src="img/shape.png" style="width: 70%; height: 70%">
							<figcaption>Solo la geometría de la imagen.</figcaption>
						</figure>
						<div>
							<div style="display:inline-block; width: 50%; vertical-align: top; float:left">
								<figure>
									<img src="img/color.png">
									<figcaption>Solo el color de la imagen.</figcaption>
								</figure>
							</div>
							<div style="display: inline-block; width: 50%; vertical-align: top; float:right">	
								<figure>
									<img src="img/both.png">
									<figcaption>Usando los dos tipos de información.</figcaption>
								</figure>
							</div>
						</div>
					</section>
					<section>
						<h2>Curva ROC del mejor modelo</h2>
						<img src="img/roc.png" style="width: 85%">
					</section>
				</section>
				<section data-transition="zoom">
					<section>
						<h2>Conclusiones</h2>
						<ul>
							<li>La aproximación de usar solo el color no es correcta debido a las variaciones de color que existen dentro de una misma clase. Solo aportan valor para un tamaño de BOW pequeño.</li>
							<li>El cambiar las imágenes al espacio de color HSV nos permite hacer que los colores sean independientes a las condiciones de luz de la imagen.</li>
						</ul>
					</section>
					<section>
						<h2>Conclusiones</h2>
						<ul>
							<li>El mejor modelo es el que utiliza SVM con solo información geométrica de la imágen extraída usando KAZE y con un tamaño $k=500$ para el K-Means que calcula el BOW.</li>
							<li>El tamaño del BOW y la calidad del clustering, junto con la calidad de los puntos extraídos y el detector usado son fundamental para que los algoritmos de aprendizaje realicen un buen trabajo.</li>
						</ul>
					</section>
				</section>
			</div>
		</div>


		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,

				math: {
			        mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
			        config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
			    },

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/math/math.js', async: true }
				]
			});
		</script>
	</body>
</html>
